1
00:00:00,000 --> 00:00:03,824
In this chapter I'll introduce the Claude 3 family and what

2
00:00:03,824 --> 00:00:07,359
it means for enterprise AI. Claude 3 offers multiple model

3
00:00:07,359 --> 00:00:10,003
sizes targeted at different tradeoffs — intelligence,

4
00:00:10,003 --> 00:00:13,157
latency, and cost — and all have multimodal vision

5
00:00:13,157 --> 00:00:14,364
capabilities.

6
00:00:14,364 --> 00:00:17,531
Compared to Claude 2, these models are faster, more

7
00:00:17,531 --> 00:00:20,251
steerable, and produce better out-of-the-box results with

8
00:00:20,251 --> 00:00:21,351
fewer prompt

9
00:00:21,351 --> 00:00:22,051
tweaks.

10
00:00:22,051 --> 00:00:24,770
Anthropic positions the largest model as state-of-the-art

11
00:00:24,770 --> 00:00:27,427
on published benchmarks while smaller variants deliver

12
00:00:27,427 --> 00:00:30,266
improved speed and lower cost compared to older

13
00:00:30,266 --> 00:00:31,473
alternatives.

14
00:00:31,473 --> 00:00:34,680
Finally, Claude 3 is optimized to process long context

15
00:00:34,680 --> 00:00:37,927
quickly — for example, reading large documents in seconds

16
00:00:37,927 --> 00:00:40,438
— which unlocks more ambitious workflows in

17
00:00:40,438 --> 00:00:41,538
production.

18
00:00:41,538 --> 00:00:44,877
Here we focus on raw performance and Claude 3’s vision

19
00:00:44,877 --> 00:00:46,088
capabilities.

20
00:00:46,088 --> 00:00:49,726
The family includes very fast variants — Claude 3 Haiku is

21
00:00:49,726 --> 00:00:52,402
highlighted for class-leading latency — while larger

22
00:00:52,402 --> 00:00:55,102
models improve accuracy on hard, open-ended problems,

23
00:00:55,102 --> 00:00:57,269
sometimes by roughly 2x versus previous

24
00:00:57,269 --> 00:00:58,469
generations.

25
00:00:58,469 --> 00:01:01,468
Vision models are trained for enterprise content: charts,

26
00:01:01,468 --> 00:01:04,286
graphs, technical diagrams, handwritten notes, and images

27
00:01:04,286 --> 00:01:06,224
from business workflows like insurance

28
00:01:06,224 --> 00:01:06,924
claims.

29
00:01:06,924 --> 00:01:09,577
That combination of speed, accuracy, and multimodal

30
00:01:09,577 --> 00:01:12,781
understanding makes Claude 3 suited to tasks that require

31
00:01:12,781 --> 00:01:15,710
both rapid processing and reliable outputs across long

32
00:01:15,710 --> 00:01:17,994
contexts, such as document summarization and

33
00:01:17,994 --> 00:01:19,215
evidence-based

34
00:01:19,215 --> 00:01:19,615
Q&A.

35
00:01:19,615 --> 00:01:22,346
Safety and compliance are core to adopting Claude in

36
00:01:22,346 --> 00:01:23,346
enterprise

37
00:01:23,346 --> 00:01:24,246
settings.

38
00:01:24,246 --> 00:01:26,786
Anthropic emphasizes resistance to jailbreaks — with

39
00:01:26,786 --> 00:01:29,111
research and internal evaluations showing strong

40
00:01:29,111 --> 00:01:32,019
performance — and leverages Constitutional AI and RLHF to

41
00:01:32,019 --> 00:01:34,488
reduce harmful outputs while improving the model’s

42
00:01:34,488 --> 00:01:35,488
judgments.

43
00:01:35,488 --> 00:01:38,264
For regulated industries, Claude supports HIPAA and SOC2

44
00:01:38,264 --> 00:01:41,076
assurances and benefits from AWS Bedrock integrations and

45
00:01:41,076 --> 00:01:43,834
enterprise security credentials that simplify compliance

46
00:01:43,834 --> 00:01:45,091
and FedRAMP-adjacent

47
00:01:45,091 --> 00:01:46,091
workflows.

48
00:01:46,091 --> 00:01:48,596
Operationally, Anthropic invests in red teaming and

49
00:01:48,596 --> 00:01:51,443
safety-focused training to reduce false positives and make

50
00:01:51,443 --> 00:01:53,912
refusals more accurate, enabling use in high-trust

51
00:01:53,912 --> 00:01:55,353
scenarios like healthcare and

52
00:01:55,353 --> 00:01:56,153
finance.

53
00:01:56,153 --> 00:01:58,860
This chapter walks through what teams actually do with

54
00:01:58,860 --> 00:01:59,560
Claude.

55
00:01:59,560 --> 00:02:02,208
Common applications include content generation (copy,

56
00:02:02,208 --> 00:02:05,076
documentation, email drafts), long-form summarization and

57
00:02:05,076 --> 00:02:07,503
Q&A across books, contracts, and transcripts, and

58
00:02:07,503 --> 00:02:10,371
sophisticated classification and extraction of structured

59
00:02:10,371 --> 00:02:10,871
data.

60
00:02:10,871 --> 00:02:13,773
In developer workflows Claude supports code generation, SQL

61
00:02:13,773 --> 00:02:15,341
synthesis, unit tests, and code

62
00:02:15,341 --> 00:02:16,541
explanation.

63
00:02:16,541 --> 00:02:19,321
It also works as a dialogue agent for customer support,

64
00:02:19,321 --> 00:02:20,593
tutoring, or internal

65
00:02:20,593 --> 00:02:21,493
advisors.

66
00:02:21,493 --> 00:02:23,993
Two important enablers across use cases are native

67
00:02:23,993 --> 00:02:26,861
multilingual handling (200+ languages) and RAG integration

68
00:02:26,861 --> 00:02:29,702
to ground responses in customer data for higher precision

69
00:02:29,702 --> 00:02:30,702
and reduced

70
00:02:30,702 --> 00:02:31,923
hallucination.

71
00:02:31,923 --> 00:02:34,777
Prompt engineering is an empirical craft: prompts contain

72
00:02:34,777 --> 00:02:37,236
context, tone, background data, clear task rules,

73
00:02:37,236 --> 00:02:38,592
examples, and conversation

74
00:02:38,592 --> 00:02:39,392
history.

75
00:02:39,392 --> 00:02:42,218
Good prompts are tested against comprehensive testcases,

76
00:02:42,218 --> 00:02:45,021
including edge cases like poor input, ambiguous queries,

77
00:02:45,021 --> 00:02:45,921
or missing

78
00:02:45,921 --> 00:02:46,421
data.

79
00:02:46,421 --> 00:02:49,017
Consumer prompts tend to be shorter and exploratory;

80
00:02:49,017 --> 00:02:51,447
enterprise prompts are templatized with variable

81
00:02:51,447 --> 00:02:53,142
placeholders for high-throughput

82
00:02:53,142 --> 00:02:54,242
automation.

83
00:02:54,242 --> 00:02:56,940
With Claude 3 you must use the Messages API and respect

84
00:02:56,940 --> 00:02:59,539
user/assistant/system role formatting — separating

85
00:02:59,539 --> 00:03:02,195
system-level instructions from user content improves

86
00:03:02,195 --> 00:03:03,833
steerability and reduces leakage

87
00:03:03,833 --> 00:03:04,433
risks.

88
00:03:04,433 --> 00:03:07,391
The guiding principle: iterate, measure, and refine prompts

89
00:03:07,391 --> 00:03:08,630
against held-out

90
00:03:08,630 --> 00:03:09,230
evals.

91
00:03:09,230 --> 00:03:12,095
This section covers practical techniques that materially

92
00:03:12,095 --> 00:03:13,295
improve model

93
00:03:13,295 --> 00:03:14,095
outputs.

94
00:03:14,095 --> 00:03:17,486
Be explicit and direct, number steps for complex tasks, and

95
00:03:17,486 --> 00:03:19,362
assign roles to shift tone and

96
00:03:19,362 --> 00:03:20,262
accuracy.

97
00:03:20,262 --> 00:03:22,732
XML tags and template variables make prompts

98
00:03:22,732 --> 00:03:24,279
machine-friendly and minimize

99
00:03:24,279 --> 00:03:25,279
ambiguity;

100
00:03:25,279 --> 00:03:28,374
pre-filling the assistant field steers format and increases

101
00:03:28,374 --> 00:03:29,274
accuracy.

102
00:03:29,274 --> 00:03:32,454
Asking Claude to think step-by-step or to output internal

103
00:03:32,454 --> 00:03:35,319
reasoning (in tagged blocks) often improves correctness,

104
00:03:35,319 --> 00:03:38,107
especially for multi-step logic, while n-shot examples

105
00:03:38,107 --> 00:03:39,982
reduce variance at the cost of

106
00:03:39,982 --> 00:03:40,682
tokens.

107
00:03:40,682 --> 00:03:43,894
For complex workflows use chaining — have Claude generate,

108
00:03:43,894 --> 00:03:47,190
then evaluate or rewrite against rubrics — and feed long

109
00:03:47,190 --> 00:03:49,384
documents in tagged blocks before asking

110
00:03:49,384 --> 00:03:50,384
questions.

111
00:03:50,384 --> 00:03:53,520
Tools and retrieval make Claude practical for real systems.

112
00:03:53,520 --> 00:03:56,539
Tool use means Claude decides which function to call and

113
00:03:56,539 --> 00:03:57,339
with what

114
00:03:57,339 --> 00:03:58,339
arguments;

115
00:03:58,339 --> 00:04:01,330
the client executes the function and returns results for

116
00:04:01,330 --> 00:04:02,130
Claude to

117
00:04:02,130 --> 00:04:02,930
consume.

118
00:04:02,930 --> 00:04:05,970
Describe functions and call syntax clearly in prompts and

119
00:04:05,970 --> 00:04:08,865
use XML tags around <function_calls> so outputs can be

120
00:04:08,865 --> 00:04:09,565
parsed.

121
00:04:09,565 --> 00:04:12,626
RAG complements this by embedding and retrieving documents

122
00:04:12,626 --> 00:04:14,915
from vector DBs so answers are grounded in

123
00:04:14,915 --> 00:04:15,815
evidence;

124
00:04:15,815 --> 00:04:18,780
good RAG systems include chunking strategy, reranking or

125
00:04:18,780 --> 00:04:21,453
Claude-driven query-rewrites, and selection of the

126
00:04:21,453 --> 00:04:22,553
appropriate

127
00:04:22,553 --> 00:04:23,453
database.

128
00:04:23,453 --> 00:04:26,514
Together, tooling and RAG reduce hallucinations and enable

129
00:04:26,514 --> 00:04:27,846
accurate, actionable

130
00:04:27,846 --> 00:04:28,846
responses.

131
00:04:28,846 --> 00:04:32,378
We wrap up with empirical evaluations, migration notes, and

132
00:04:32,378 --> 00:04:33,078
API best

133
00:04:33,078 --> 00:04:34,078
practices.

134
00:04:34,078 --> 00:04:37,924
Evals are the backbone of prompt engineering — use MCQs for

135
00:04:37,924 --> 00:04:41,158
closed form checks, exact match for string-level tasks,

136
00:04:41,158 --> 00:04:43,214
and open-answer rubrics for nuanced

137
00:04:43,214 --> 00:04:44,214
judgments.

138
00:04:44,214 --> 00:04:47,797
Run held-out test suites and include edge cases to avoid

139
00:04:47,797 --> 00:04:48,997
regressions.

140
00:04:48,997 --> 00:04:52,667
Migrating from Claude 2 to 3 often means moving to the

141
00:04:52,667 --> 00:04:55,779
Messages API, leveraging assistant prefill, and trimming

142
00:04:55,779 --> 00:04:58,518
prompts because Claude 3 can do more with

143
00:04:58,518 --> 00:04:59,018
less.

144
00:04:59,018 --> 00:05:02,217
Finally, tune max_tokens to guard response length, use

145
00:05:02,217 --> 00:05:05,450
stop_sequences (paired with XML tags) to limit outputs,

146
00:05:05,450 --> 00:05:09,069
and set temperature near 0 for analytical tasks or closer

147
00:05:09,069 --> 00:05:09,669
to 1 for

148
00:05:09,669 --> 00:05:10,769
creativity.
